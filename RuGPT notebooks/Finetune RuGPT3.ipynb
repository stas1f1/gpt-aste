{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3RHDK81QqrET",
    "tags": []
   },
   "source": [
    "# Finetune ruGPT3Large on SRE data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eK10D3MSpYty",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Install enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3404,
     "status": "ok",
     "timestamp": 1668165792669,
     "user": {
      "displayName": "Станислав Чумаков",
      "userId": "08332204488166174685"
     },
     "user_tz": -180
    },
    "id": "asqMueYPeIgK",
    "outputId": "376ab2ac-d940-4ec5-dfb3-c1bed6f57e11"
   },
   "outputs": [],
   "source": [
    "!pip3 install urllib3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17085,
     "status": "ok",
     "timestamp": 1668165809745,
     "user": {
      "displayName": "Станислав Чумаков",
      "userId": "08332204488166174685"
     },
     "user_tz": -180
    },
    "id": "yPqtVgbkeTx7",
    "outputId": "68184189-f7ac-449e-b5ce-e7b8c8cb467f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting transformers==3.0.2\n",
      "  Using cached transformers-3.0.2-py3-none-any.whl (769 kB)\n",
      "Requirement already satisfied: sacremoses in /data/home/asurikov/.local/lib/python3.8/site-packages (from transformers==3.0.2) (0.0.53)\n",
      "Requirement already satisfied: filelock in /devtools/anaconda/lib/python3.8/site-packages (from transformers==3.0.2) (3.6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /devtools/anaconda/lib/python3.8/site-packages (from transformers==3.0.2) (4.64.1)\n",
      "Collecting tokenizers==0.8.1.rc1\n",
      "  Using cached tokenizers-0.8.1rc1-cp38-cp38-manylinux1_x86_64.whl (3.0 MB)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /data/home/asurikov/.local/lib/python3.8/site-packages (from transformers==3.0.2) (0.1.97)\n",
      "Requirement already satisfied: numpy in /data/home/asurikov/.local/lib/python3.8/site-packages (from transformers==3.0.2) (1.23.4)\n",
      "Requirement already satisfied: packaging in /devtools/anaconda/lib/python3.8/site-packages (from transformers==3.0.2) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /data/home/asurikov/.local/lib/python3.8/site-packages (from transformers==3.0.2) (2022.10.31)\n",
      "Requirement already satisfied: requests in /devtools/anaconda/lib/python3.8/site-packages (from transformers==3.0.2) (2.28.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /devtools/anaconda/lib/python3.8/site-packages (from packaging->transformers==3.0.2) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /data/home/asurikov/.local/lib/python3.8/site-packages (from requests->transformers==3.0.2) (1.25.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /devtools/anaconda/lib/python3.8/site-packages (from requests->transformers==3.0.2) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /devtools/anaconda/lib/python3.8/site-packages (from requests->transformers==3.0.2) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /devtools/anaconda/lib/python3.8/site-packages (from requests->transformers==3.0.2) (3.4)\n",
      "Requirement already satisfied: joblib in /data/home/asurikov/.local/lib/python3.8/site-packages (from sacremoses->transformers==3.0.2) (1.2.0)\n",
      "Requirement already satisfied: six in /devtools/anaconda/lib/python3.8/site-packages (from sacremoses->transformers==3.0.2) (1.16.0)\n",
      "Requirement already satisfied: click in /devtools/anaconda/lib/python3.8/site-packages (from sacremoses->transformers==3.0.2) (8.0.4)\n",
      "Installing collected packages: tokenizers, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.13.2\n",
      "    Uninstalling tokenizers-0.13.2:\n",
      "      Successfully uninstalled tokenizers-0.13.2\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.24.0\n",
      "    Uninstalling transformers-4.24.0:\n",
      "      Successfully uninstalled transformers-4.24.0\n",
      "\u001b[33m  WARNING: The script transformers-cli is installed in '/data/home/asurikov/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sentence-transformers 2.2.2 requires transformers<5.0.0,>=4.6.0, but you have transformers 3.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed tokenizers-0.8.1rc1 transformers-3.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==3.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls ~/tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall torch -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat /usr/local/cuda/version.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!TMPDIR=~/tmp pip install torch==1.8.1+cu101 torchvision==0.9.1+cu101 torchaudio==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m wget https://raw.githubusercontent.com/sberbank-ai/ru-gpts/master/pretrain_transformers.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s9_GTdDDKyUI"
   },
   "source": [
    "##Apex setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PCLZyw0uK0pY"
   },
   "source": [
    "Clone data, move apex/apex out of the apex folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2750,
     "status": "ok",
     "timestamp": 1668165821667,
     "user": {
      "displayName": "Станислав Чумаков",
      "userId": "08332204488166174685"
     },
     "user_tz": -180
    },
    "id": "sNL0wxHUdgd3",
    "outputId": "053309b3-0dfd-4fda-8188-bed8c5edf69a"
   },
   "outputs": [],
   "source": [
    "!git clone -b 22.04-dev https://github.com/NVIDIA/apex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aCXhnwuWeHm1"
   },
   "outputs": [],
   "source": [
    "!cd apex\n",
    "!pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GDYi1TVTrtkO",
    "tags": []
   },
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Finetune SRE GPT3Large.ipynb'\n",
      "'GPT_models_evaluation_n_shots (4).ipynb'\n",
      " SRE-15\n",
      " apex\n",
      " apex_\n",
      " aste_pipeline.ipynb\n",
      " examples\n",
      " ghostdriver.log\n",
      " gpt2_cached_lm_1024_train.txt\n",
      " pretrain_transformers.py\n",
      " rugpt3l\n",
      " rugpt3large_based_on_gpt2_finetuned-50x3\n",
      " rugpt3small_based_on_gpt2_finetuned-50x3\n",
      " runs\n",
      " train.txt\n",
      " valid.txt\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "f5EtK-jerBRv"
   },
   "outputs": [],
   "source": [
    "data_path_car = \"~/ASTE/SRE-15/SentiRuEval_car_train_short_edited.csv\"\n",
    "data_path_rest = \"~/ASTE/SRE-15/SentiRuEval_rest_train_short_edited.csv\"\n",
    "data_path_film = \"~/ASTE/SRE-15/SentiRuEval_film_train_short_edited.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 659
    },
    "executionInfo": {
     "elapsed": 1139,
     "status": "ok",
     "timestamp": 1668165879892,
     "user": {
      "displayName": "Станислав Чумаков",
      "userId": "08332204488166174685"
     },
     "user_tz": -180
    },
    "id": "OXdNbrq3rgzq",
    "outputId": "3d0624b2-686a-4389-f056-06012774a3f6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_car = pd.read_csv(data_path_car)\n",
    "data_rest = pd.read_csv(data_path_rest)\n",
    "data_film = pd.read_csv(data_path_film)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "0wJbXNTiGgIh"
   },
   "outputs": [],
   "source": [
    "def format_columns(text, response):\n",
    "  return '<s>Текст: ' + text + '\\n' + response.strip()+'</s>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "d_ma4HsjI7D_"
   },
   "outputs": [],
   "source": [
    "texts_car = list(map(format_columns, data_car[\"Text\"], data_car[\"Response\"]))\n",
    "texts_rest = list(map(format_columns, data_rest[\"Text\"], data_rest[\"Response\"]))\n",
    "texts_film = list(map(format_columns, data_film[\"Text\"], data_film[\"Response\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 222,
     "status": "ok",
     "timestamp": 1668165895837,
     "user": {
      "displayName": "Станислав Чумаков",
      "userId": "08332204488166174685"
     },
     "user_tz": -180
    },
    "id": "2wNhRq_cJMe9",
    "outputId": "5b699542-f1ff-4165-c7c1-c6dc6cac7853"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>Текст: Недавно купил этот автомобиль. Авто отличное! Двигатель 2,5 литра, турбодизель. Прежний хозяин сказал при продаже, что масло не жрет, солярку тоже, летит как угорелая! Так оно и есть. 140 км/ч нормальная крейсерская скорость. Вообще немцы умеют делать автомобили. Дорогу держит отлично, так как достаточно широкая машина. Тормоза все дисковые. Главное передний привод, по сравнению с другими немецкими автомобилями. Такими как мерседес и бмв этого же класса. Места в автомобиле очень много. Не тесно даже, когда сидят пять взрослых человек. Багажное отделение тоже огромно. Влезла стиральная машина. По соотношению цена - качество, отличный автомобиль. Больше никогда не сяду за руль российского автомбиля! Всем рекомендую Ауди. \n",
      "Авто: отличное: положительно \n",
      "двигатель: 2,5 литра, турбодизель: положительно \n",
      "прежний хозяин: сказал при продаже, что масло не жрет, солярку тоже, летит как угорелая: положительно \n",
      "крейсерская скорость: 140 км/ч: положительно \n",
      "дорогу держит: отлично: положительно \n",
      "тормоза: все дисковые: положительно \n",
      "передний привод: по сравнению с другими немецкими автомобилями: положительно \n",
      "места: очень много: положительно \n",
      "багажное отделение: огромно: положительно \n",
      "соотношение цена - качество: отличный автомобиль: положительно</s>\n"
     ]
    }
   ],
   "source": [
    "print(texts_car[0])\n",
    "#print(texts_rest[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5E7OavaKObi"
   },
   "source": [
    "We use the first 50 texts as train, other data as val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "RpftlwiwKN8T"
   },
   "outputs": [],
   "source": [
    "split = 50\n",
    "train = texts_car[:split] + texts_rest[:split] + texts_film[:split]\n",
    "valid = texts_car[split:] + texts_rest[split:] + texts_film[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 225,
     "status": "ok",
     "timestamp": 1668165911817,
     "user": {
      "displayName": "Станислав Чумаков",
      "userId": "08332204488166174685"
     },
     "user_tz": -180
    },
    "id": "2T0gN6gqr9pa",
    "outputId": "a33d4fed-6250-49ed-a8fc-7fe07877b56f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 132)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "ZPB8rrVPr-kh"
   },
   "outputs": [],
   "source": [
    "with open(\"train.txt\", \"w\") as file:\n",
    "    file.write(\"\\n\\n\".join(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "HP5_nk_0sAB0"
   },
   "outputs": [],
   "source": [
    "with open(\"valid.txt\", \"w\") as file:\n",
    "    file.write(\"\\n\\n\".join(valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NitGcEKPsDQE"
   },
   "source": [
    "## Run finetuning\n",
    "The following code download our model and tokenizer from transformers and finetune model essays.\n",
    "\n",
    "This took aroung ten minutes and obtain perplexity = tensor(13.8065)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Dec 14 13:41:43 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.126.02   Driver Version: 418.126.02   CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    44W / 300W |     11MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "5vL07XFvsBBU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/14/2022 13:41:47 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: True\n",
      "12/14/2022 13:41:48 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/sberbank-ai/rugpt3large_based_on_gpt2/config.json from cache at /data/home/asurikov/.cache/torch/transformers/53218293a9edec913332b4f2d178496a60f98d64a1af74f92984804152f9404c.02a103afdbdbf4896cc41fc6495e47b7e5e2f353a287fe98d178e669be028903\n",
      "12/14/2022 13:41:48 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 2048,\n",
      "  \"n_embd\": 1536,\n",
      "  \"n_head\": 16,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 24,\n",
      "  \"n_positions\": 2048,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "12/14/2022 13:41:49 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/sberbank-ai/rugpt3large_based_on_gpt2/config.json from cache at /data/home/asurikov/.cache/torch/transformers/53218293a9edec913332b4f2d178496a60f98d64a1af74f92984804152f9404c.02a103afdbdbf4896cc41fc6495e47b7e5e2f353a287fe98d178e669be028903\n",
      "12/14/2022 13:41:49 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 2048,\n",
      "  \"n_embd\": 1536,\n",
      "  \"n_head\": 16,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 24,\n",
      "  \"n_positions\": 2048,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "12/14/2022 13:41:49 - INFO - transformers.tokenization_utils_base -   Model name 'sberbank-ai/rugpt3large_based_on_gpt2' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming 'sberbank-ai/rugpt3large_based_on_gpt2' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "12/14/2022 13:41:53 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/sberbank-ai/rugpt3large_based_on_gpt2/vocab.json from cache at /data/home/asurikov/.cache/torch/transformers/39e50567636d4014628a4fb0b7665a179a6109d96765eb4e6a10e9f2306f963d.de52bc5880aff0437c7f24c33b71ecae48f6f03f0449dfe933503132c6c1cc26\n",
      "12/14/2022 13:41:53 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/sberbank-ai/rugpt3large_based_on_gpt2/merges.txt from cache at /data/home/asurikov/.cache/torch/transformers/0a94bcfc9ca640e268e53959b05f2ebe267a5cb686289b46cac4ffac589eac40.5885500c9887f152893bfadf3b511a9105243c57bfc45889e3552bdc61090032\n",
      "12/14/2022 13:41:53 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/sberbank-ai/rugpt3large_based_on_gpt2/added_tokens.json from cache at None\n",
      "12/14/2022 13:41:53 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/sberbank-ai/rugpt3large_based_on_gpt2/special_tokens_map.json from cache at None\n",
      "12/14/2022 13:41:53 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/sberbank-ai/rugpt3large_based_on_gpt2/tokenizer_config.json from cache at None\n",
      "12/14/2022 13:41:53 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/sberbank-ai/rugpt3large_based_on_gpt2/tokenizer.json from cache at None\n",
      "/data/home/asurikov/.local/lib/python3.8/site-packages/transformers/modeling_auto.py:796: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n",
      "12/14/2022 13:41:54 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/sberbank-ai/rugpt3large_based_on_gpt2/pytorch_model.bin from cache at /data/home/asurikov/.cache/torch/transformers/be77a43067f153a210035209f17a2a6fc3cafc3c186781e080a27a9571c6529a.5bdac7adaf803c2b7192441aba3020af4140f7177089f8f95940a0c073059a31\n",
      "12/14/2022 13:42:36 - INFO - transformers.modeling_utils -   All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "12/14/2022 13:42:36 - INFO - transformers.modeling_utils -   All the weights of GPT2LMHeadModel were initialized from the model checkpoint at sberbank-ai/rugpt3large_based_on_gpt2.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "12/14/2022 13:42:45 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_by_block=False, block_by_block_with_newline=True, block_size=2048, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=True, do_train=True, eval_all_checkpoints=False, eval_data_file='valid.txt', evaluate_during_training=False, fp16=True, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=False, mlm_probability=0.15, model_name_or_path='sberbank-ai/rugpt3large_based_on_gpt2', model_type='gpt2', n_gpu=1, no_cuda=False, num_train_epochs=6.0, output_dir='rugpt3l', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='train.txt', warmup_steps=0, weight_decay=0.01)\n",
      "12/14/2022 13:42:45 - INFO - __main__ -   Creating features from dataset file at train.txt\n",
      "12/14/2022 13:42:45 - WARNING - transformers.tokenization_utils_base -   Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n",
      "12/14/2022 13:42:47 - INFO - __main__ -   ***** Running training *****\n",
      "12/14/2022 13:42:47 - INFO - __main__ -     Num examples = 151\n",
      "12/14/2022 13:42:47 - INFO - __main__ -     Num Epochs = 6\n",
      "12/14/2022 13:42:47 - INFO - __main__ -     Instantaneous batch size per GPU = 4\n",
      "12/14/2022 13:42:47 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "12/14/2022 13:42:47 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
      "12/14/2022 13:42:47 - INFO - __main__ -     Total optimization steps = 228\n",
      "Epoch:   0%|                                              | 0/6 [00:00<?, ?it/s]\n",
      "Iteration:   0%|                                         | 0/38 [00:00<?, ?it/s]\u001b[A/data/home/asurikov/.local/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:122: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Seems like `optimizer.step()` has been overridden after learning rate scheduler \"\n",
      "\n",
      "Iteration:   3%|▊                                | 1/38 [00:00<00:29,  1.27it/s]\u001b[A\n",
      "Iteration:   5%|█▋                               | 2/38 [00:01<00:23,  1.54it/s]\u001b[A\n",
      "Iteration:   8%|██▌                              | 3/38 [00:01<00:21,  1.60it/s]\u001b[A\n",
      "Iteration:  11%|███▍                             | 4/38 [00:02<00:19,  1.75it/s]\u001b[A\n",
      "Iteration:  13%|████▎                            | 5/38 [00:03<00:19,  1.67it/s]\u001b[A\n",
      "Iteration:  16%|█████▏                           | 6/38 [00:03<00:19,  1.68it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "\n",
      "Iteration:  18%|██████                           | 7/38 [00:04<00:17,  1.76it/s]\u001b[A\n",
      "Iteration:  21%|██████▉                          | 8/38 [00:04<00:16,  1.78it/s]\u001b[A\n",
      "Iteration:  24%|███████▊                         | 9/38 [00:05<00:18,  1.56it/s]\u001b[A\n",
      "Iteration:  26%|████████▍                       | 10/38 [00:06<00:17,  1.61it/s]\u001b[A\n",
      "Iteration:  29%|█████████▎                      | 11/38 [00:06<00:16,  1.65it/s]\u001b[A\n",
      "Iteration:  32%|██████████                      | 12/38 [00:07<00:16,  1.62it/s]\u001b[A\n",
      "Iteration:  34%|██████████▉                     | 13/38 [00:07<00:14,  1.70it/s]\u001b[A\n",
      "Iteration:  37%|███████████▊                    | 14/38 [00:08<00:14,  1.65it/s]\u001b[A\n",
      "Iteration:  39%|████████████▋                   | 15/38 [00:09<00:13,  1.64it/s]\u001b[A\n",
      "Iteration:  42%|█████████████▍                  | 16/38 [00:09<00:13,  1.61it/s]\u001b[A\n",
      "Iteration:  45%|██████████████▎                 | 17/38 [00:10<00:13,  1.56it/s]\u001b[A\n",
      "Iteration:  47%|███████████████▏                | 18/38 [00:10<00:11,  1.69it/s]\u001b[A\n",
      "Iteration:  50%|████████████████                | 19/38 [00:11<00:11,  1.59it/s]\u001b[A\n",
      "Iteration:  53%|████████████████▊               | 20/38 [00:12<00:10,  1.66it/s]\u001b[A\n",
      "Iteration:  55%|█████████████████▋              | 21/38 [00:12<00:09,  1.75it/s]\u001b[A\n",
      "Iteration:  58%|██████████████████▌             | 22/38 [00:13<00:08,  1.84it/s]\u001b[A\n",
      "Iteration:  61%|███████████████████▎            | 23/38 [00:13<00:07,  1.89it/s]\u001b[A\n",
      "Iteration:  63%|████████████████████▏           | 24/38 [00:14<00:07,  1.83it/s]\u001b[A\n",
      "Iteration:  66%|█████████████████████           | 25/38 [00:14<00:07,  1.73it/s]\u001b[A\n",
      "Iteration:  68%|█████████████████████▉          | 26/38 [00:15<00:07,  1.67it/s]\u001b[A\n",
      "Iteration:  71%|██████████████████████▋         | 27/38 [00:16<00:06,  1.71it/s]\u001b[A\n",
      "Iteration:  74%|███████████████████████▌        | 28/38 [00:16<00:05,  1.74it/s]\u001b[A\n",
      "Iteration:  76%|████████████████████████▍       | 29/38 [00:17<00:04,  1.83it/s]\u001b[A\n",
      "Iteration:  79%|█████████████████████████▎      | 30/38 [00:17<00:04,  1.84it/s]\u001b[A\n",
      "Iteration:  82%|██████████████████████████      | 31/38 [00:18<00:03,  1.75it/s]\u001b[A\n",
      "Iteration:  84%|██████████████████████████▉     | 32/38 [00:18<00:03,  1.82it/s]\u001b[A\n",
      "Iteration:  87%|███████████████████████████▊    | 33/38 [00:19<00:02,  1.85it/s]\u001b[A\n",
      "Iteration:  89%|████████████████████████████▋   | 34/38 [00:19<00:02,  1.78it/s]\u001b[A\n",
      "Iteration:  92%|█████████████████████████████▍  | 35/38 [00:20<00:01,  1.74it/s]\u001b[A\n",
      "Iteration:  95%|██████████████████████████████▎ | 36/38 [00:21<00:01,  1.83it/s]\u001b[A\n",
      "Iteration:  97%|███████████████████████████████▏| 37/38 [00:21<00:00,  1.78it/s]\u001b[A\n",
      "Iteration: 100%|████████████████████████████████| 38/38 [00:22<00:00,  1.72it/s]\u001b[A\n",
      "Epoch:  17%|██████▎                               | 1/6 [00:22<01:50, 22.06s/it]\n",
      "Iteration:   0%|                                         | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   3%|▊                                | 1/38 [00:00<00:22,  1.65it/s]\u001b[A\n",
      "Iteration:   5%|█▋                               | 2/38 [00:01<00:21,  1.70it/s]\u001b[A\n",
      "Iteration:   8%|██▌                              | 3/38 [00:01<00:19,  1.84it/s]\u001b[A\n",
      "Iteration:  11%|███▍                             | 4/38 [00:02<00:19,  1.71it/s]\u001b[A\n",
      "Iteration:  13%|████▎                            | 5/38 [00:02<00:18,  1.75it/s]\u001b[A\n",
      "Iteration:  16%|█████▏                           | 6/38 [00:03<00:18,  1.72it/s]\u001b[A\n",
      "Iteration:  18%|██████                           | 7/38 [00:04<00:19,  1.61it/s]\u001b[A\n",
      "Iteration:  21%|██████▉                          | 8/38 [00:04<00:17,  1.67it/s]\u001b[A\n",
      "Iteration:  24%|███████▊                         | 9/38 [00:05<00:17,  1.66it/s]\u001b[A\n",
      "Iteration:  26%|████████▍                       | 10/38 [00:05<00:16,  1.73it/s]\u001b[A\n",
      "Iteration:  29%|█████████▎                      | 11/38 [00:06<00:15,  1.80it/s]\u001b[A\n",
      "Iteration:  32%|██████████                      | 12/38 [00:07<00:15,  1.72it/s]\u001b[A\n",
      "Iteration:  34%|██████████▉                     | 13/38 [00:07<00:13,  1.81it/s]\u001b[A\n",
      "Iteration:  37%|███████████▊                    | 14/38 [00:08<00:13,  1.72it/s]\u001b[A\n",
      "Iteration:  39%|████████████▋                   | 15/38 [00:08<00:13,  1.71it/s]\u001b[A\n",
      "Iteration:  42%|█████████████▍                  | 16/38 [00:09<00:13,  1.62it/s]\u001b[A\n",
      "Iteration:  45%|██████████████▎                 | 17/38 [00:09<00:12,  1.68it/s]\u001b[A\n",
      "Iteration:  47%|███████████████▏                | 18/38 [00:10<00:11,  1.78it/s]\u001b[A\n",
      "Iteration:  50%|████████████████                | 19/38 [00:11<00:10,  1.74it/s]\u001b[A\n",
      "Iteration:  53%|████████████████▊               | 20/38 [00:11<00:09,  1.81it/s]\u001b[A\n",
      "Iteration:  55%|█████████████████▋              | 21/38 [00:12<00:10,  1.59it/s]\u001b[A\n",
      "Iteration:  58%|██████████████████▌             | 22/38 [00:12<00:09,  1.72it/s]\u001b[A\n",
      "Iteration:  61%|███████████████████▎            | 23/38 [00:13<00:08,  1.72it/s]\u001b[A\n",
      "Iteration:  63%|████████████████████▏           | 24/38 [00:13<00:07,  1.80it/s]\u001b[A\n",
      "Iteration:  66%|█████████████████████           | 25/38 [00:14<00:07,  1.79it/s]\u001b[A\n",
      "Iteration:  68%|█████████████████████▉          | 26/38 [00:14<00:06,  1.86it/s]\u001b[A\n",
      "Iteration:  71%|██████████████████████▋         | 27/38 [00:15<00:06,  1.75it/s]\u001b[A\n",
      "Iteration:  74%|███████████████████████▌        | 28/38 [00:16<00:05,  1.78it/s]\u001b[A\n",
      "Iteration:  76%|████████████████████████▍       | 29/38 [00:16<00:05,  1.75it/s]\u001b[A\n",
      "Iteration:  79%|█████████████████████████▎      | 30/38 [00:17<00:04,  1.77it/s]\u001b[A\n",
      "Iteration:  82%|██████████████████████████      | 31/38 [00:17<00:03,  1.85it/s]\u001b[A\n",
      "Iteration:  84%|██████████████████████████▉     | 32/38 [00:18<00:03,  1.72it/s]\u001b[A\n",
      "Iteration:  87%|███████████████████████████▊    | 33/38 [00:19<00:02,  1.72it/s]\u001b[A\n",
      "Iteration:  89%|████████████████████████████▋   | 34/38 [00:19<00:02,  1.75it/s]\u001b[A\n",
      "Iteration:  92%|█████████████████████████████▍  | 35/38 [00:20<00:01,  1.74it/s]\u001b[A\n",
      "Iteration:  95%|██████████████████████████████▎ | 36/38 [00:20<00:01,  1.85it/s]\u001b[A\n",
      "Iteration:  97%|███████████████████████████████▏| 37/38 [00:21<00:00,  1.90it/s]\u001b[A\n",
      "Iteration: 100%|████████████████████████████████| 38/38 [00:21<00:00,  1.75it/s]\u001b[A\n",
      "Epoch:  33%|████████████▋                         | 2/6 [00:43<01:27, 21.85s/it]\n",
      "Iteration:   0%|                                         | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   3%|▊                                | 1/38 [00:00<00:21,  1.71it/s]\u001b[A\n",
      "Iteration:   5%|█▋                               | 2/38 [00:01<00:18,  1.99it/s]\u001b[A\n",
      "Iteration:   8%|██▌                              | 3/38 [00:01<00:16,  2.10it/s]\u001b[A\n",
      "Iteration:  11%|███▍                             | 4/38 [00:02<00:18,  1.87it/s]\u001b[A\n",
      "Iteration:  13%|████▎                            | 5/38 [00:02<00:17,  1.84it/s]\u001b[A\n",
      "Iteration:  16%|█████▏                           | 6/38 [00:03<00:18,  1.69it/s]\u001b[A\n",
      "Iteration:  18%|██████                           | 7/38 [00:03<00:17,  1.76it/s]\u001b[A\n",
      "Iteration:  21%|██████▉                          | 8/38 [00:04<00:17,  1.72it/s]\u001b[A\n",
      "Iteration:  24%|███████▊                         | 9/38 [00:05<00:16,  1.74it/s]\u001b[A\n",
      "Iteration:  26%|████████▍                       | 10/38 [00:05<00:16,  1.73it/s]\u001b[A\n",
      "Iteration:  29%|█████████▎                      | 11/38 [00:06<00:15,  1.71it/s]\u001b[A\n",
      "Iteration:  32%|██████████                      | 12/38 [00:06<00:14,  1.79it/s]\u001b[A\n",
      "Iteration:  34%|██████████▉                     | 13/38 [00:07<00:13,  1.88it/s]\u001b[A\n",
      "Iteration:  37%|███████████▊                    | 14/38 [00:07<00:12,  1.92it/s]\u001b[A\n",
      "Iteration:  39%|████████████▋                   | 15/38 [00:08<00:13,  1.66it/s]\u001b[A\n",
      "Iteration:  42%|█████████████▍                  | 16/38 [00:09<00:13,  1.67it/s]\u001b[A\n",
      "Iteration:  45%|██████████████▎                 | 17/38 [00:09<00:12,  1.70it/s]\u001b[A\n",
      "Iteration:  47%|███████████████▏                | 18/38 [00:10<00:11,  1.74it/s]\u001b[A\n",
      "Iteration:  50%|████████████████                | 19/38 [00:10<00:10,  1.80it/s]\u001b[A\n",
      "Iteration:  53%|████████████████▊               | 20/38 [00:11<00:11,  1.57it/s]\u001b[A\n",
      "Iteration:  55%|█████████████████▋              | 21/38 [00:12<00:10,  1.57it/s]\u001b[A\n",
      "Iteration:  58%|██████████████████▌             | 22/38 [00:12<00:10,  1.59it/s]\u001b[A\n",
      "Iteration:  61%|███████████████████▎            | 23/38 [00:13<00:09,  1.60it/s]\u001b[A\n",
      "Iteration:  63%|████████████████████▏           | 24/38 [00:13<00:08,  1.72it/s]\u001b[A\n",
      "Iteration:  66%|█████████████████████           | 25/38 [00:14<00:07,  1.67it/s]\u001b[A\n",
      "Iteration:  68%|█████████████████████▉          | 26/38 [00:15<00:07,  1.60it/s]\u001b[A\n",
      "Iteration:  71%|██████████████████████▋         | 27/38 [00:15<00:06,  1.62it/s]\u001b[A\n",
      "Iteration:  74%|███████████████████████▌        | 28/38 [00:16<00:06,  1.61it/s]\u001b[A\n",
      "Iteration:  76%|████████████████████████▍       | 29/38 [00:16<00:05,  1.71it/s]\u001b[A\n",
      "Iteration:  79%|█████████████████████████▎      | 30/38 [00:17<00:04,  1.62it/s]\u001b[A\n",
      "Iteration:  82%|██████████████████████████      | 31/38 [00:18<00:04,  1.60it/s]\u001b[A\n",
      "Iteration:  84%|██████████████████████████▉     | 32/38 [00:18<00:03,  1.68it/s]\u001b[A\n",
      "Iteration:  87%|███████████████████████████▊    | 33/38 [00:19<00:03,  1.64it/s]\u001b[A\n",
      "Iteration:  89%|████████████████████████████▋   | 34/38 [00:20<00:02,  1.62it/s]\u001b[A\n",
      "Iteration:  92%|█████████████████████████████▍  | 35/38 [00:20<00:01,  1.74it/s]\u001b[A\n",
      "Iteration:  95%|██████████████████████████████▎ | 36/38 [00:21<00:01,  1.72it/s]\u001b[A\n",
      "Iteration:  97%|███████████████████████████████▏| 37/38 [00:21<00:00,  1.71it/s]\u001b[A\n",
      "Iteration: 100%|████████████████████████████████| 38/38 [00:22<00:00,  1.70it/s]\u001b[A\n",
      "Epoch:  50%|███████████████████                   | 3/6 [01:06<01:06, 22.07s/it]\n",
      "Iteration:   0%|                                         | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   3%|▊                                | 1/38 [00:00<00:18,  1.97it/s]\u001b[A\n",
      "Iteration:   5%|█▋                               | 2/38 [00:01<00:18,  1.97it/s]\u001b[A\n",
      "Iteration:   8%|██▌                              | 3/38 [00:01<00:19,  1.75it/s]\u001b[A\n",
      "Iteration:  11%|███▍                             | 4/38 [00:02<00:19,  1.78it/s]\u001b[A\n",
      "Iteration:  13%|████▎                            | 5/38 [00:02<00:17,  1.86it/s]\u001b[A\n",
      "Iteration:  16%|█████▏                           | 6/38 [00:03<00:16,  1.90it/s]\u001b[A\n",
      "Iteration:  18%|██████                           | 7/38 [00:03<00:17,  1.77it/s]\u001b[A\n",
      "Iteration:  21%|██████▉                          | 8/38 [00:04<00:17,  1.69it/s]\u001b[A\n",
      "Iteration:  24%|███████▊                         | 9/38 [00:05<00:16,  1.73it/s]\u001b[A\n",
      "Iteration:  26%|████████▍                       | 10/38 [00:05<00:16,  1.72it/s]\u001b[A\n",
      "Iteration:  29%|█████████▎                      | 11/38 [00:06<00:16,  1.68it/s]\u001b[A\n",
      "Iteration:  32%|██████████                      | 12/38 [00:06<00:16,  1.59it/s]\u001b[A\n",
      "Iteration:  34%|██████████▉                     | 13/38 [00:07<00:14,  1.73it/s]\u001b[A\n",
      "Iteration:  37%|███████████▊                    | 14/38 [00:08<00:14,  1.71it/s]\u001b[A\n",
      "Iteration:  39%|████████████▋                   | 15/38 [00:08<00:13,  1.72it/s]\u001b[A\n",
      "Iteration:  42%|█████████████▍                  | 16/38 [00:09<00:12,  1.72it/s]\u001b[A\n",
      "Iteration:  45%|██████████████▎                 | 17/38 [00:09<00:11,  1.76it/s]\u001b[A\n",
      "Iteration:  47%|███████████████▏                | 18/38 [00:10<00:12,  1.63it/s]\u001b[A\n",
      "Iteration:  50%|████████████████                | 19/38 [00:11<00:11,  1.65it/s]\u001b[A\n",
      "Iteration:  53%|████████████████▊               | 20/38 [00:11<00:10,  1.65it/s]\u001b[A\n",
      "Iteration:  55%|█████████████████▋              | 21/38 [00:12<00:10,  1.67it/s]\u001b[A\n",
      "Iteration:  58%|██████████████████▌             | 22/38 [00:12<00:08,  1.79it/s]\u001b[A\n",
      "Iteration:  61%|███████████████████▎            | 23/38 [00:13<00:08,  1.86it/s]\u001b[A\n",
      "Iteration:  63%|████████████████████▏           | 24/38 [00:13<00:08,  1.75it/s]\u001b[A\n",
      "Iteration:  66%|█████████████████████           | 25/38 [00:14<00:07,  1.83it/s]\u001b[A\n",
      "Iteration:  68%|█████████████████████▉          | 26/38 [00:14<00:06,  1.85it/s]\u001b[A\n",
      "Iteration:  71%|██████████████████████▋         | 27/38 [00:15<00:06,  1.81it/s]\u001b[A\n",
      "Iteration:  74%|███████████████████████▌        | 28/38 [00:15<00:05,  1.80it/s]\u001b[A\n",
      "Iteration:  76%|████████████████████████▍       | 29/38 [00:16<00:05,  1.72it/s]\u001b[A\n",
      "Iteration:  79%|█████████████████████████▎      | 30/38 [00:17<00:04,  1.78it/s]\u001b[A\n",
      "Iteration:  82%|██████████████████████████      | 31/38 [00:17<00:03,  1.75it/s]\u001b[A\n",
      "Iteration:  84%|██████████████████████████▉     | 32/38 [00:18<00:04,  1.50it/s]\u001b[A\n",
      "Iteration:  87%|███████████████████████████▊    | 33/38 [00:19<00:03,  1.64it/s]\u001b[A\n",
      "Iteration:  89%|████████████████████████████▋   | 34/38 [00:19<00:02,  1.70it/s]\u001b[A\n",
      "Iteration:  92%|█████████████████████████████▍  | 35/38 [00:20<00:01,  1.75it/s]\u001b[A\n",
      "Iteration:  95%|██████████████████████████████▎ | 36/38 [00:20<00:01,  1.77it/s]\u001b[A\n",
      "Iteration:  97%|███████████████████████████████▏| 37/38 [00:21<00:00,  1.74it/s]\u001b[A\n",
      "Iteration: 100%|████████████████████████████████| 38/38 [00:21<00:00,  1.74it/s]\u001b[A\n",
      "Epoch:  67%|█████████████████████████▎            | 4/6 [01:27<00:43, 21.96s/it]\n",
      "Iteration:   0%|                                         | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   3%|▊                                | 1/38 [00:00<00:24,  1.54it/s]\u001b[A\n",
      "Iteration:   5%|█▋                               | 2/38 [00:01<00:22,  1.63it/s]\u001b[A\n",
      "Iteration:   8%|██▌                              | 3/38 [00:01<00:20,  1.70it/s]\u001b[A\n",
      "Iteration:  11%|███▍                             | 4/38 [00:02<00:20,  1.69it/s]\u001b[A\n",
      "Iteration:  13%|████▎                            | 5/38 [00:02<00:17,  1.86it/s]\u001b[A\n",
      "Iteration:  16%|█████▏                           | 6/38 [00:03<00:16,  1.93it/s]\u001b[A\n",
      "Iteration:  18%|██████                           | 7/38 [00:03<00:15,  2.02it/s]\u001b[A\n",
      "Iteration:  21%|██████▉                          | 8/38 [00:04<00:17,  1.67it/s]\u001b[A\n",
      "Iteration:  24%|███████▊                         | 9/38 [00:05<00:17,  1.66it/s]\u001b[A\n",
      "Iteration:  26%|████████▍                       | 10/38 [00:05<00:16,  1.71it/s]\u001b[A\n",
      "Iteration:  29%|█████████▎                      | 11/38 [00:06<00:15,  1.71it/s]\u001b[A\n",
      "Iteration:  32%|██████████                      | 12/38 [00:06<00:15,  1.67it/s]\u001b[A\n",
      "Iteration:  34%|██████████▉                     | 13/38 [00:07<00:14,  1.68it/s]\u001b[A\n",
      "Iteration:  37%|███████████▊                    | 14/38 [00:08<00:14,  1.70it/s]\u001b[A\n",
      "Iteration:  39%|████████████▋                   | 15/38 [00:08<00:12,  1.82it/s]\u001b[A\n",
      "Iteration:  42%|█████████████▍                  | 16/38 [00:09<00:12,  1.73it/s]\u001b[A\n",
      "Iteration:  45%|██████████████▎                 | 17/38 [00:09<00:12,  1.72it/s]\u001b[A\n",
      "Iteration:  47%|███████████████▏                | 18/38 [00:10<00:12,  1.62it/s]\u001b[A\n",
      "Iteration:  50%|████████████████                | 19/38 [00:11<00:11,  1.71it/s]\u001b[A\n",
      "Iteration:  53%|████████████████▊               | 20/38 [00:11<00:10,  1.79it/s]\u001b[A\n",
      "Iteration:  55%|█████████████████▋              | 21/38 [00:12<00:09,  1.79it/s]\u001b[A\n",
      "Iteration:  58%|██████████████████▌             | 22/38 [00:12<00:09,  1.64it/s]\u001b[A\n",
      "Iteration:  61%|███████████████████▎            | 23/38 [00:13<00:09,  1.61it/s]\u001b[A\n",
      "Iteration:  63%|████████████████████▏           | 24/38 [00:13<00:08,  1.68it/s]\u001b[A\n",
      "Iteration:  66%|█████████████████████           | 25/38 [00:14<00:07,  1.71it/s]\u001b[A\n",
      "Iteration:  68%|█████████████████████▉          | 26/38 [00:15<00:07,  1.70it/s]\u001b[A\n",
      "Iteration:  71%|██████████████████████▋         | 27/38 [00:15<00:06,  1.68it/s]\u001b[A\n",
      "Iteration:  74%|███████████████████████▌        | 28/38 [00:16<00:05,  1.70it/s]\u001b[A\n",
      "Iteration:  76%|████████████████████████▍       | 29/38 [00:16<00:05,  1.66it/s]\u001b[A\n",
      "Iteration:  79%|█████████████████████████▎      | 30/38 [00:17<00:04,  1.77it/s]\u001b[A\n",
      "Iteration:  82%|██████████████████████████      | 31/38 [00:18<00:04,  1.71it/s]\u001b[A\n",
      "Iteration:  84%|██████████████████████████▉     | 32/38 [00:18<00:03,  1.79it/s]\u001b[A\n",
      "Iteration:  87%|███████████████████████████▊    | 33/38 [00:19<00:02,  1.78it/s]\u001b[A\n",
      "Iteration:  89%|████████████████████████████▋   | 34/38 [00:19<00:02,  1.71it/s]\u001b[A\n",
      "Iteration:  92%|█████████████████████████████▍  | 35/38 [00:20<00:01,  1.76it/s]\u001b[A\n",
      "Iteration:  95%|██████████████████████████████▎ | 36/38 [00:20<00:01,  1.84it/s]\u001b[A\n",
      "Iteration:  97%|███████████████████████████████▏| 37/38 [00:21<00:00,  1.87it/s]\u001b[A\n",
      "Iteration: 100%|████████████████████████████████| 38/38 [00:21<00:00,  1.74it/s]\u001b[A\n",
      "Epoch:  83%|███████████████████████████████▋      | 5/6 [01:49<00:21, 21.92s/it]\n",
      "Iteration:   0%|                                         | 0/38 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   3%|▊                                | 1/38 [00:00<00:17,  2.07it/s]\u001b[A\n",
      "Iteration:   5%|█▋                               | 2/38 [00:00<00:16,  2.13it/s]\u001b[A\n",
      "Iteration:   8%|██▌                              | 3/38 [00:01<00:19,  1.81it/s]\u001b[A\n",
      "Iteration:  11%|███▍                             | 4/38 [00:02<00:19,  1.74it/s]\u001b[A\n",
      "Iteration:  13%|████▎                            | 5/38 [00:02<00:19,  1.72it/s]\u001b[A\n",
      "Iteration:  16%|█████▏                           | 6/38 [00:03<00:17,  1.81it/s]\u001b[A\n",
      "Iteration:  18%|██████                           | 7/38 [00:03<00:16,  1.85it/s]\u001b[A\n",
      "Iteration:  21%|██████▉                          | 8/38 [00:04<00:15,  1.88it/s]\u001b[A\n",
      "Iteration:  24%|███████▊                         | 9/38 [00:04<00:15,  1.82it/s]\u001b[A\n",
      "Iteration:  26%|████████▍                       | 10/38 [00:05<00:14,  1.89it/s]\u001b[A\n",
      "Iteration:  29%|█████████▎                      | 11/38 [00:06<00:15,  1.78it/s]\u001b[A\n",
      "Iteration:  32%|██████████                      | 12/38 [00:06<00:13,  1.88it/s]\u001b[A\n",
      "Iteration:  34%|██████████▉                     | 13/38 [00:07<00:13,  1.89it/s]\u001b[A\n",
      "Iteration:  37%|███████████▊                    | 14/38 [00:07<00:13,  1.77it/s]\u001b[A\n",
      "Iteration:  39%|████████████▋                   | 15/38 [00:08<00:12,  1.83it/s]\u001b[A\n",
      "Iteration:  42%|█████████████▍                  | 16/38 [00:09<00:13,  1.58it/s]\u001b[A\n",
      "Iteration:  45%|██████████████▎                 | 17/38 [00:09<00:12,  1.65it/s]\u001b[A\n",
      "Iteration:  47%|███████████████▏                | 18/38 [00:10<00:11,  1.74it/s]\u001b[A\n",
      "Iteration:  50%|████████████████                | 19/38 [00:10<00:10,  1.79it/s]\u001b[A\n",
      "Iteration:  53%|████████████████▊               | 20/38 [00:11<00:10,  1.73it/s]\u001b[A\n",
      "Iteration:  55%|█████████████████▋              | 21/38 [00:11<00:09,  1.75it/s]\u001b[A\n",
      "Iteration:  58%|██████████████████▌             | 22/38 [00:12<00:09,  1.77it/s]\u001b[A\n",
      "Iteration:  61%|███████████████████▎            | 23/38 [00:12<00:08,  1.76it/s]\u001b[A\n",
      "Iteration:  63%|████████████████████▏           | 24/38 [00:13<00:07,  1.76it/s]\u001b[A\n",
      "Iteration:  66%|█████████████████████           | 25/38 [00:13<00:06,  1.86it/s]\u001b[A\n",
      "Iteration:  68%|█████████████████████▉          | 26/38 [00:14<00:07,  1.68it/s]\u001b[A\n",
      "Iteration:  71%|██████████████████████▋         | 27/38 [00:15<00:06,  1.77it/s]\u001b[A\n",
      "Iteration:  74%|███████████████████████▌        | 28/38 [00:15<00:05,  1.68it/s]\u001b[A\n",
      "Iteration:  76%|████████████████████████▍       | 29/38 [00:16<00:05,  1.67it/s]\u001b[A\n",
      "Iteration:  79%|█████████████████████████▎      | 30/38 [00:16<00:04,  1.69it/s]\u001b[A\n",
      "Iteration:  82%|██████████████████████████      | 31/38 [00:17<00:04,  1.64it/s]\u001b[A\n",
      "Iteration:  84%|██████████████████████████▉     | 32/38 [00:18<00:03,  1.72it/s]\u001b[A\n",
      "Iteration:  87%|███████████████████████████▊    | 33/38 [00:18<00:02,  1.68it/s]\u001b[A\n",
      "Iteration:  89%|████████████████████████████▋   | 34/38 [00:19<00:02,  1.72it/s]\u001b[A\n",
      "Iteration:  92%|█████████████████████████████▍  | 35/38 [00:20<00:01,  1.62it/s]\u001b[A\n",
      "Iteration:  95%|██████████████████████████████▎ | 36/38 [00:20<00:01,  1.63it/s]\u001b[A\n",
      "Iteration:  97%|███████████████████████████████▏| 37/38 [00:21<00:00,  1.75it/s]\u001b[A\n",
      "Iteration: 100%|████████████████████████████████| 38/38 [00:21<00:00,  1.76it/s]\u001b[A\n",
      "Epoch: 100%|██████████████████████████████████████| 6/6 [02:11<00:00, 21.88s/it]\n",
      "12/14/2022 13:44:58 - INFO - __main__ -    global_step = 228, average loss = 1.1981813005710904\n",
      "12/14/2022 13:44:58 - INFO - __main__ -   Saving model checkpoint to rugpt3l\n",
      "12/14/2022 13:44:58 - INFO - transformers.configuration_utils -   Configuration saved in rugpt3l/config.json\n",
      "12/14/2022 13:45:06 - INFO - transformers.modeling_utils -   Model weights saved in rugpt3l/pytorch_model.bin\n",
      "12/14/2022 13:45:06 - INFO - transformers.configuration_utils -   loading configuration file rugpt3l/config.json\n",
      "12/14/2022 13:45:06 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 2048,\n",
      "  \"n_embd\": 1536,\n",
      "  \"n_head\": 16,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 24,\n",
      "  \"n_positions\": 2048,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "12/14/2022 13:45:06 - INFO - transformers.modeling_utils -   loading weights file rugpt3l/pytorch_model.bin\n",
      "12/14/2022 13:45:48 - INFO - transformers.modeling_utils -   All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "12/14/2022 13:45:48 - INFO - transformers.modeling_utils -   All the weights of GPT2LMHeadModel were initialized from the model checkpoint at rugpt3l.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "12/14/2022 13:45:48 - INFO - transformers.configuration_utils -   loading configuration file rugpt3l/config.json\n",
      "12/14/2022 13:45:48 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 2048,\n",
      "  \"n_embd\": 1536,\n",
      "  \"n_head\": 16,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 24,\n",
      "  \"n_positions\": 2048,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "12/14/2022 13:45:48 - INFO - transformers.tokenization_utils_base -   Model name 'rugpt3l' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming 'rugpt3l' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "12/14/2022 13:45:48 - INFO - transformers.tokenization_utils_base -   Didn't find file rugpt3l/added_tokens.json. We won't load it.\n",
      "12/14/2022 13:45:48 - INFO - transformers.tokenization_utils_base -   Didn't find file rugpt3l/tokenizer.json. We won't load it.\n",
      "12/14/2022 13:45:48 - INFO - transformers.tokenization_utils_base -   loading file rugpt3l/vocab.json\n",
      "12/14/2022 13:45:48 - INFO - transformers.tokenization_utils_base -   loading file rugpt3l/merges.txt\n",
      "12/14/2022 13:45:48 - INFO - transformers.tokenization_utils_base -   loading file None\n",
      "12/14/2022 13:45:48 - INFO - transformers.tokenization_utils_base -   loading file rugpt3l/special_tokens_map.json\n",
      "12/14/2022 13:45:48 - INFO - transformers.tokenization_utils_base -   loading file rugpt3l/tokenizer_config.json\n",
      "12/14/2022 13:45:48 - INFO - transformers.tokenization_utils_base -   loading file None\n",
      "12/14/2022 13:45:49 - INFO - __main__ -   Evaluate the following checkpoints: ['rugpt3l']\n",
      "12/14/2022 13:45:49 - INFO - transformers.configuration_utils -   loading configuration file rugpt3l/config.json\n",
      "12/14/2022 13:45:49 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 2048,\n",
      "  \"n_embd\": 1536,\n",
      "  \"n_head\": 16,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 24,\n",
      "  \"n_positions\": 2048,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "12/14/2022 13:45:49 - INFO - transformers.modeling_utils -   loading weights file rugpt3l/pytorch_model.bin\n",
      "12/14/2022 13:46:35 - INFO - transformers.modeling_utils -   All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "12/14/2022 13:46:35 - INFO - transformers.modeling_utils -   All the weights of GPT2LMHeadModel were initialized from the model checkpoint at rugpt3l.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "12/14/2022 13:46:35 - INFO - __main__ -   Creating features from dataset file at valid.txt\n",
      "12/14/2022 13:46:35 - WARNING - transformers.tokenization_utils_base -   Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "12/14/2022 13:46:37 - INFO - __main__ -   ***** Running evaluation  *****\n",
      "12/14/2022 13:46:37 - INFO - __main__ -     Num examples = 132\n",
      "12/14/2022 13:46:37 - INFO - __main__ -     Batch size = 4\n",
      "Evaluating: 100%|███████████████████████████████| 33/33 [00:03<00:00,  9.90it/s]\n",
      "12/14/2022 13:46:40 - INFO - __main__ -   ***** Eval results  *****\n",
      "12/14/2022 13:46:40 - INFO - __main__ -     perplexity = tensor(12.2508)\n"
     ]
    }
   ],
   "source": [
    "!python pretrain_transformers.py \\\n",
    "    --output_dir=rugpt3l\\\n",
    "    --model_type=gpt2 \\\n",
    "    --model_name_or_path=sberbank-ai/rugpt3large_based_on_gpt2 \\\n",
    "    --do_train \\\n",
    "    --train_data_file=train.txt \\\n",
    "    --do_eval \\\n",
    "    --fp16 \\\n",
    "    --eval_data_file=valid.txt \\\n",
    "    --per_gpu_train_batch_size 4 \\\n",
    "    --gradient_accumulation_steps 1 \\\n",
    "    --num_train_epochs 6 \\\n",
    "    --block_size 2048 \\\n",
    "    --overwrite_output_dir\\\n",
    "    --block_by_block_with_newline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i31Kko3PNM_B"
   },
   "source": [
    "## Check our model (load in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "0wz-cO74NJKx"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"rugpt3large_based_on_gpt2_finetuned-50+50\"\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(checkpoint_path)\n",
    "model = GPT2LMHeadModel.from_pretrained(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "vpaKXktUOlQu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 1536)\n",
       "    (wpe): Embedding(2048, 1536)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (12): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (13): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (14): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (15): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (16): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (17): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (18): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (19): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (20): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (21): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (22): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (23): Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1536, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Текст: Большой и вместительный автомобиль. Едет мягко и в тоже время не покачивает как на корабле. Места для задних пассажиров очень предостаточно и как показывает личный опыт, с весом 100 с лишним килограмм и ростом за 180 сантиметров прекрасно умещаемся. Едешь и разуешься, шум в салоне практически отсутствует, красота, можно говорить не напрягаясь, все хорошо слышно. Проехав не одну тысячу километров по бездорожью понимаешь полезность полного привода, ни разу не подвел. Кому не ездить по лесам и карьерам, можно попробовать и просто переднеприводный, но только по трассе, так как сам по себе автомобиль тяжелый.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Текст: ' + data_car.iloc[73]['Text'].strip() + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12964,
     "status": "ok",
     "timestamp": 1668130626591,
     "user": {
      "displayName": "Станислав Чумаков",
      "userId": "08332204488166174685"
     },
     "user_tz": -180
    },
    "id": "3EEwOB15NYUT",
    "outputId": "53685ea0-7b24-4a50-d291-1a3634c68923"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Текст: Большой и вместительный автомобиль. Едет мягко и в тоже время не покачивает как на корабле.\n",
      "Места для задних пассажиров очень предостаточно и как показывает личный опыт, с весом 100 с лишним\n",
      "килограмм и ростом за 180 сантиметров прекрасно умещаемся. Едешь и разуешься, шум в салоне\n",
      "практически отсутствует, красота, можно говорить не напрягаясь, все хорошо слышно. Проехав не одну\n",
      "тысячу километров по бездорожью понимаешь полезность полного привода, ни разу не подвел. Кому не\n",
      "ездить по лесам и карьерам, можно попробовать и просто переднеприводный, но только по трассе, так\n",
      "как сам по себе автомобиль тяжелый.\n",
      "\n",
      "Машина: надежная, неприхотливая: положительно \n",
      "Машина: быстрая: положительно \n",
      "Автомобиль: просторный: положительно \n",
      "Езда: мягкая: положительно \n",
      "Места: для задних пассажиров очень много: положительно \n",
      "Шум: практически отсутствует: положительно \n",
      "Проезд: не одну тысячу километров: положительно\n",
      "\n",
      "<pad><pad><pad><pad><pad> размещения<pad><pad><pad><pad> финала работа: положительно \n",
      "автомобиль: надежный, неприхотливый: положительно \n",
      "машина: быстрая: нейтрально \n",
      "места: для задних сидений очень много: положительно\n",
      "\n",
      " Оставалось только пожалеть, что у нас в стране не выпускают внедорожники, которые могли бы составить достойную конкуренцию этим немецким автомобилям.\n",
      "\n",
      "<pad><pad> размещения<pad> финала работа: негативно \n",
      "автомобиль, просторный: положительно\n",
      "\n",
      " remaining Volkswagen Polo: положительно \n",
      "места для задних пассажиров: очень много: положительно, просторно\n",
      "\n",
      "<pad><pad> завершения работа: положительно ройзен: положительно \n",
      "шум: практически отсутствует: нейтрально\n",
      "\n",
      " Volkswagen Polo: просторный: нейтрально\n",
      "Места: много: положительно, комфортно\n",
      "\n",
      " Volkswagen Polow: просторный: комфортно\n",
      "\n",
      " Volkswagen Volkswagen Polow: комфортно\n",
      "\n",
      " Автомобиль: надежный, непритязательный: положительно \n",
      "цена\n"
     ]
    }
   ],
   "source": [
    "from textwrap import wrap\n",
    "\n",
    "prompt = 'Текст: ' + data_car.iloc[73]['Text'].strip() + '\\n'\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "input_ids = input_ids.cuda()\n",
    "out = model.generate(\n",
    "        input_ids, \n",
    "        min_length=100, \n",
    "        max_length=400, \n",
    "        eos_token_id=5, \n",
    "        pad_token_id=1,\n",
    "        top_k=5,\n",
    "        top_p=0.0,\n",
    "        no_repeat_ngram_size=5\n",
    ")\n",
    "generated_text = list(map(tokenizer.decode, out))[0]\n",
    "print('\\n' + '\\n'.join(wrap(prompt, 100)) + '\\n')\n",
    "print(generated_text[len(prompt):])\n",
    "#print(generated_text[len(prompt):].split(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2N6ylGPt1F5"
   },
   "source": [
    "## Check our model (interctive script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1606,
     "status": "ok",
     "timestamp": 1668119306459,
     "user": {
      "displayName": "Станислав Чумаков",
      "userId": "08332204488166174685"
     },
     "user_tz": -180
    },
    "id": "JRlAAsIbsHdf",
    "outputId": "48f2de26-d561-4673-ccc7-6cfdcbb97a5f"
   },
   "outputs": [],
   "source": [
    "!python generate_transformers.py \\\n",
    "    --model_type=gpt2 \\\n",
    "    --model_name_or_path=comment_model \\\n",
    "    --k=5 \\\n",
    "    --p=0.95 \\\n",
    "    --length=50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G6FrdJGfoOCo"
   },
   "source": [
    "Context >>> Is it\n",
    "\n",
    "ruGPT:\n",
    "Is it's the case that #Microsoft is using #SAP to manage #Microsoft’s business?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9xrK05vCoUXh"
   },
   "source": [
    "Context >>> It  is\n",
    "\n",
    "ruGPT:\n",
    "It is the only one that I've been trying to do.\n",
    "Siri is on the verge of death, and I'm not aware of why she has to be on the verge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aOo1x1ArogLs"
   },
   "source": [
    "Context >>> Why\n",
    "\n",
    "ruGPT:\n",
    "Why do I go here?  I'm wondering if I can use the #Microsoft Windows 8 Pro for the #WindowsPhone phone?  Thanks! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D34DPrwvozgd"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": [
    {
     "file_id": "1bwNxmVJMJ3x_N5ylS-nylkQpHUAF0DES",
     "timestamp": 1666978286165
    },
    {
     "file_id": "1asD3mi9SdygVNWCE94bIPpciTrbbPIWd",
     "timestamp": 1605862234662
    },
    {
     "file_id": "1h6r6Qg9xwyIzz6-FXgB9tIjAzce0gc2d",
     "timestamp": 1605190861790
    },
    {
     "file_id": "https://github.com/sberbank-ai/ru-gpts/blob/master/examples/Finetune_ruGPT3Small.ipynb",
     "timestamp": 1604407812564
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
